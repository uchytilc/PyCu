


from numba import cuda
import numpy as np

import cudaimpl
import core

@cuda.jit()
def kernel(out, i):
	test = interval(i[0],i[1])
	# test = interval(2.5,5.5)
	# print(test.lo, test.hi)

	# a = -test
	# print(a.lo, a.hi)

	################################

	# a = test + test
	# b = test + 2
	# c = 2 + test

	# a = test - test
	# b = test - 2
	# c = 2 - test

	# a = test*test
	# b = test*2
	# c = 2*test

	# print(a.lo, a.hi)
	# print(b.lo, b.hi)
	# print(c.lo, c.hi)

	################################

	# a = min(test, 2 + test)
	# b = min(test, 3)
	# c = min(3, test)

	# a = core.min(test, 2 + test)
	# b = core.min(test, 3)
	# c = core.min(3, test)

	# a = max(test, 2 + test)
	# b = max(test, 3)
	# c = max(3, test)

	# a = core.max(test, 2 + test)
	# b = core.max(test, 3)
	# c = core.max(3, test)

	# print(a.lo, a.hi)
	# print(b.lo, b.hi)
	# print(c.lo, c.hi)

	################################

	# a = abs(test)
	# print(a.lo, a.hi)

	################################

	# a = test <= test
	# b = test <= 1
	# c = 1 <= test

	# a = test < test
	# b = test < 1
	# c = 1 < test

	# a = test > test
	# b = test > 1
	# c = 1 > test

	# a = test >= test
	# b = test >= 1
	# c = 1 >= test

	# a = test == test
	# b = test == 1
	# c = 1 == test

	# a = test != test
	# b = test != 1
	# c = 1 != test

	# out[0] = a
	# out[1] = b
	# out[2] = c

	################################

	# test += 1
	# test -= 1
	# test *= 1
	# test /= 1

	# print(test.lo, test.hi)
	# test *= 1
	# print(test.lo, test.hi)

	# a = round(test)
	# print(a.lo, a.hi)


	################################

	a = core.cos(test)

	# a = core.sin(test)

	print(a.lo, a.hi)

	# a = core.exp(test)
	# print(a.lo, a.hi)

# i = np.array([2.5, 5.5], dtype = np.float32)
# i = np.array([-4, -1.5], dtype = np.float32)

i = np.array([9, 10], dtype = np.float32)

out = np.zeros(3, dtype = np.float32)
kernel[1, 1](out, i)
# print(out)









# numba/numba/cpython/numbers.py
# # with builder.if_then(builder.not_(is_overflow), likely=True):
# #		 # Note LLVM will optimize this to a single divmod instruction,
# #		 # if available on the target CPU (e.g. x86).
# #		 xdivy = builder.sdiv(x, y)
# #		 xmody = builder.srem(x, y)

# #		 y_xor_xmody_ltz = builder.icmp_signed('<', builder.xor(y, xmody), ZERO)
# #		 xmody_istrue = builder.icmp_signed('!=', xmody, ZERO)
# #		 cond = builder.and_(xmody_istrue, y_xor_xmody_ltz)

# #	 with builder.if_then(builder.not_(is_overflow), likely=True):
# #		 # Note LLVM will optimize this to a single divmod instruction,
# #		 # if available on the target CPU (e.g. x86).
# #		 xdivy = builder.sdiv(x, y)
# #		 xmody = builder.srem(x, y)

# #		 y_xor_xmody_ltz = builder.icmp_signed('<', builder.xor(y, xmody), ZERO)
# #		 xmody_istrue = builder.icmp_signed('!=', xmody, ZERO)
# #		 cond = builder.and_(xmody_istrue, y_xor_xmody_ltz)

# #		 with builder.if_else(cond) as (if_different_signs, if_same_signs):
# #			 with if_same_signs:
# #				 builder.store(xdivy, resdiv)
# #				 builder.store(xmody, resmod)

# #			 with if_different_signs:
# #				 builder.store(builder.sub(xdivy, ONE), resdiv)
# #				 builder.store(builder.add(xmody, y), resmod)


















# double2float_rd = (core.double2float_rd, signature(types.float32, types.float64))
# double2float_ru = (core.double2float_ru, signature(types.float32, types.float64))

# ceilf =(core.ceilf, signature(types.float32, types.float32))
# floorf = (core.floorf, signature(types.float32, types.float32))
# roundf = (core.roundf, signature(types.float32, types.float32))
# fsqrt_rd = (core.fsqrt_rd, signature(types.float32, types.float32))
# fsqrt_ru = (core.fsqrt_ru, signature(types.float32, types.float32))

# exp = (core.exp, signature(types.float64, types.float64))




# fadd_rd = (core.fadd_rd, signature(types.float32, types.float32, types.float32))
# fadd_ru = (core.fadd_ru, signature(types.float32, types.float32, types.float32))
# fsub_rd = (core.fsub_rd, signature(types.float32, types.float32, types.float32))
# fsub_ru = (core.fsub_ru, signature(types.float32, types.float32, types.float32))
# fmul_rd = (core.fmul_rd, signature(types.float32, types.float32, types.float32))
# fmul_ru = (core.fmul_ru, signature(types.float32, types.float32, types.float32))
# fdiv_rd = (core.fdiv_rd, signature(types.float32, types.float32, types.float32))
# fdiv_ru = (core.fdiv_ru, signature(types.float32, types.float32, types.float32))
# fminf = (core.fminf, signature(types.float32, types.float32, types.float32))
# fmaxf = (core.fmaxf, signature(types.float32, types.float32, types.float32))
# fneg = (operator.neg, signature(types.float32, types.float32))
# fabs = (abs, signature(types.float32, types.float32))



# requires_builder = {'cast'}
# def context_ops(*libfuncs):
# 	def decorator(func):
# 		def wrapper(context, builder, sig, args, ops, *intervals):
# 			for libfunc in libfuncs:
# 				if libfuncs in requires_builder:
# 					ops.append(context_caller(context, builder, libfunc))
# 				else:
# 					ops.append(getattr(context, libfunc))
# 			if getattr(func, 'ops_wrapper', False):
# 				return func(context, builder, sig, args, ops, *intervals)
# 			return func(*intervals, *ops)
# 		wrapper.ops_wrapper = True
# 		return wrapper
# 	return decorator

# def builder_ops(*libfuncs):
# 	#helper decorator to grab all builder functions listed in builder_ops decorator
# 	def decorator(func):
# 		def wrapper(context, builder, sig, args, ops, *intervals):
# 			ops += [getattr(builder, libfunc) for libfunc in libfuncs]
# 			if getattr(func, 'ops_wrapper', False):
# 				return func(context, builder, sig, args, ops, *intervals)
# 			return func(*intervals, *ops)
# 		wrapper.ops_wrapper = True
# 		return wrapper
# 	return decorator

# def mathimpl_ops(*libfuncs):
# 	#helper decorator to grab all mathimpl functions listed in mathimpl_ops decorator
# 	def decorator(func):
# 		def wrapper(context, builder, sig, args, ops, *intervals):
# 			ops += [mathimpl_caller(builder, libfunc) for libfunc in libfuncs]
# 			return func(*intervals, *ops)
# 		wrapper.ops_wrapper = True
# 		return wrapper
# 	return decorator

# def libdevice_ops(*libfuncs):
# 	#helper decorator to grab all libdevice functions listed in libdevice_ops decorator
# 	def decorator(func):
# 		def wrapper(context, builder, sig, args, ops, *intervals):
# 			ops += [libdevice_caller(context, builder, libfunc, libsig) for libfunc, libsig in libfuncs]
# 			if getattr(func, 'ops_wrapper', False):
# 				return func(context, builder, sig, args, ops, *intervals)
# 			return func(*intervals, *ops)
# 		wrapper.ops_wrapper = True
# 		return wrapper
# 	return decorator


# def context_caller(context, builder, libfunc):
# 	op = getattr(context, libfunc)
# 	def context_op_caller(*args):
# 		return op(builder, *args)
# 	return context_op_caller

# def mathimpl_caller(builder, libfunc):
# 	def mathimpl_op_caller(*args):
# 		return op(builder, *args)
# 	return mathimpl_op_caller

# def libdevice_caller(context, builder, libfunc, sig):
# 	#if isinstance(libfunc):
# 		#libfunc =  getattr(core, libfunc)
# 	op = context.get_function(libfunc, sig) #getattr(core, libfunc)
# 	def libfunc_op_caller(*args):
# 		return op(builder, [*args])
# 	return libfunc_op_caller



# @context_ops('get_constant')
# @builder_ops('if_else', 'fcmp_unordered')
# @libdevice_ops(fabs, fmaxf, fneg)
# def abs_interval(x,y,*ops): 
# 	get_constant, if_else, fcmp_unordered, fabs, fmaxf, fneg = ops

# 	zero = get_constant(types.float32, 0)

# 	positive = fcmp_unordered('>=', x.lo, zero)
# 	with if_else(positive) as (true, false):
# 		with true:
# 			y.lo = x.lo
# 			y.hi = x.hi
# 		with false:
# 			negative = fcmp_unordered('<', x.hi, zero)
# 			with if_else(negative) as (true, false):
# 				with true:
# 					y.lo = fneg(x.hi)
# 					y.hi = fneg(x.lo)
# 				with false:
# 					y.lo = zero
# 					y.hi = fmaxf(fabs(x.lo), fabs(x.hi))
# 	return y
